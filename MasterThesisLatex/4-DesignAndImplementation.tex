\chapter{Design and Implementation}

The main goal of this thesis is to achieve a high accuracy on the recognition of asbestos fibers in microscopic images. Since no baseline is available, one needs to be established first. The dataset consists of only a few hundred images, so data augmentation will is an important tool. Several architectures are evaluated with and without transfer-learning. Architectures are tweaked to better accomodate the ressource constraints posed by Hardware restrictions.

\section{Problem Description}

Talk about the asbestos problem. The size of the images and the GPU restrictions on memory

\section{Data Augmentation}

How and why has the data been augmented?

\section{AlexNext}

It has not been possible to get a baseline for the current performance or even an accurate estimation of human performance in the detection of asbestos fibers in the provided images. Therefore, AlexNet was used to create a baseline on which improvements may be observed and would allow discussions on architectures and their performance. The hyper-parameters learning rate and learning rate decay have been optimized with grid search by running every configuration five times, averaging the results and choosing the hyper-parameters that performed best.

\begin{table}[t] \centering
\ra{1.3}
\caption{AlexNet accuracies for baseline with optimized hyper-parameters}
\begin{tabular}{@{}rrrr@{}}
\toprule & learning rate & lr-decay & accuracy \\
\midrule
AlexNet		& 0.1 		& 5		& 52.18\%  \\
AlexNet		& 0.05 		& 5		& 53.64\%  \\
AlexNet		& 0.01 		& 5		& 53.37\%  \\
AlexNet		& 0.005 		& 5		& 53.67\%  \\
AlexNet		& 0.001 		& 5		& 78.82\%  \\
AlexNet		& 0.0005 		& 5		& 78.55\%  \\
AlexNet		& 0.0001 		& 5		& 77.09\%  \\
\bottomrule
\end{tabular}
\label{tbl:similarity-test-map}
\end{table}


\section{Inception / ResNet}

Talk about other architectures and why they are important

\section{SigOpt Optimization}

What is SigOpt and why did I use it?
