% 4 - Design and Implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 4.x - Data Augmentation

% VGG
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

% ResNet
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% 4.x - Transfer Learning

@inproceedings{sharif2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={806--813},
  year={2014}
}

@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}

@article{sermanet2013overfeat,
  title={Overfeat: Integrated recognition, localization and detection using convolutional networks},
  author={Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Micha{\"e}l and Fergus, Rob and LeCun, Yann},
  journal={arXiv preprint arXiv:1312.6229},
  year={2013}
}

@inproceedings{carreira2016human,
  title={Human pose estimation with iterative error feedback},
  author={Carreira, Joao and Agrawal, Pulkit and Fragkiadaki, Katerina and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4733--4742},
  year={2016}
}

@inproceedings{dai2016instance,
  title={Instance-aware semantic segmentation via multi-task network cascades},
  author={Dai, Jifeng and He, Kaiming and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3150--3158},
  year={2016}
}

@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2625--2634},
  year={2015}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

% Experiments show that ImageNet pre-training speeds up convergence early in training,
% but not necessarily provide regularization or improve final target task accuracies.
@article{he2018rethinking,
  title={Rethinking ImageNet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  journal={arXiv preprint arXiv:1811.08883},
  year={2018}
}

% Huh et al. question if pre-training on ImageNet really is that data-hungry since
% reducing classes or images in the pre-training resulted in very modest accuracy
% decline in the target domain !!! They basically play around with AlexNet pre-training
% to find the important parameters why pre-training is good and when it starts to
% deteriorate.
@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}